{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092b3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dpipe.io import load\n",
    "from dpipe.dataset.wrappers import apply, cache_methods\n",
    "from dpipe.im.metrics import dice_score, iou\n",
    "from ood.dataset.cc359 import CC359\n",
    "from ood.dataset.utils import Rescale3D, scale_mri\n",
    "from ood.paths import CC359_DATA_PATH\n",
    "from ood.torch.module.unet_mc_dropout import UNet3D_MC_Dropout\n",
    "from ood.utils import sdice\n",
    "from ood.metric.ood_metric import calc_ood_scores\n",
    "\n",
    "\n",
    "data_path = CC359_DATA_PATH\n",
    "\n",
    "# if `voxel_spacing[i]` is `None` when `i`-th dimension will be used without scaling\n",
    "voxel_spacing = (1, 0.95, 0.95)\n",
    "sdice_metric = lambda x, y, i: sdice(x, y, dataset.load_spacing(i), 1)\n",
    "\n",
    "dataset = apply(Rescale3D(CC359(data_path), voxel_spacing), load_image=scale_mri)\n",
    "\n",
    "in_distr_id = 1\n",
    "n_folds = 6\n",
    "ood_ids = [i for i in range(n_folds) if i != in_distr_id]\n",
    "n_seeds = 5\n",
    "bin_threshold = 0.5\n",
    "eps = 1e-8\n",
    "\n",
    "experiment_dir = '/mount/sdc/experiments/ood_playground/cc359/ensemble/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd70e1",
   "metadata": {},
   "source": [
    "## Dice drop with domain shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09556507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In distribution: 0.9816\n",
      "OOD fold 0: 0.9517\n",
      "OOD fold 2: 0.6995\n",
      "OOD fold 3: 0.9606\n",
      "OOD fold 4: 0.9151\n",
      "OOD fold 5: 0.8860\n",
      "In distribution: 0.9786\n",
      "OOD fold 0: 0.9427\n",
      "OOD fold 2: 0.8180\n",
      "OOD fold 3: 0.9468\n",
      "OOD fold 4: 0.9212\n",
      "OOD fold 5: 0.8992\n",
      "In distribution: 0.9809\n",
      "OOD fold 0: 0.9541\n",
      "OOD fold 2: 0.8248\n",
      "OOD fold 3: 0.9598\n",
      "OOD fold 4: 0.9443\n",
      "OOD fold 5: 0.9084\n",
      "In distribution: 0.9807\n",
      "OOD fold 0: 0.9412\n",
      "OOD fold 2: 0.7124\n",
      "OOD fold 3: 0.9571\n",
      "OOD fold 4: 0.8927\n",
      "OOD fold 5: 0.8836\n",
      "In distribution: 0.9790\n",
      "OOD fold 0: 0.9245\n",
      "OOD fold 2: 0.6794\n",
      "OOD fold 3: 0.9371\n",
      "OOD fold 4: 0.7828\n",
      "OOD fold 5: 0.8899\n",
      "Fold 0:\tood = True\t0.9429 ± 0.0205\n",
      "Fold 1:\tood = False\t0.9802 ± 0.0023\n",
      "Fold 2:\tood = True\t0.7468 ± 0.1212\n",
      "Fold 3:\tood = True\t0.9523 ± 0.0177\n",
      "Fold 4:\tood = True\t0.8912 ± 0.1110\n",
      "Fold 5:\tood = True\t0.8934 ± 0.0180\n",
      "\n",
      "In distr:\t0.9802 ± 0.0023\n",
      "OOD:\t\t0.8853 ± 0.1625\n"
     ]
    }
   ],
   "source": [
    "ood_metrics = np.zeros((n_folds, n_seeds))\n",
    "\n",
    "for seed in range(n_seeds):\n",
    "    base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/')\n",
    "    with open(os.path.join(base_dir, 'test_metrics', 'dice_score.json')) as file:\n",
    "        metrics = json.load(file)\n",
    "\n",
    "    ids = set(dataset.df[dataset.df['fold'] == in_distr_id].index)\n",
    "    metric_keys = set(metrics.keys())\n",
    "    ids = metric_keys.intersection(ids)\n",
    "\n",
    "    in_distr_metric = np.mean([metrics[uid] for uid in ids])\n",
    "    ood_metrics[in_distr_id, seed] = in_distr_metric\n",
    "    print(f'In distribution: {in_distr_metric:.4f}')\n",
    "\n",
    "    for fold_id in ood_ids:\n",
    "        ids = list(dataset.df[dataset.df['fold'] == fold_id].index)\n",
    "\n",
    "        ood_metric = np.mean([metrics[uid] for uid in ids])\n",
    "        ood_metrics[fold_id, seed] = ood_metric\n",
    "        print(f'OOD fold {fold_id}: {ood_metric:.4f}')\n",
    "        \n",
    "means = ood_metrics.mean(axis=1)\n",
    "stds = ood_metrics.std(axis=1)\n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(f'Fold {i}:\\tood = {i != in_distr_id}\\t{means[i]:.4f} ± {1.96 * stds[i]:.4f}')\n",
    "    \n",
    "print()\n",
    "ood_ids = [i for i in range(n_folds) if i != in_distr_id]\n",
    "print(f'In distr:\\t{means[in_distr_id]:.4f} ± {1.96 * stds[in_distr_id]:.4f}')\n",
    "print(f'OOD:\\t\\t{ood_metrics[ood_ids].mean():.4f} ± {1.96 * ood_metrics[ood_ids].std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d08aff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09489999999999998"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9802 - 0.8853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566747b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In distribution: 0.9116\n",
      "OOD fold 0: 0.7130\n",
      "OOD fold 2: 0.1953\n",
      "OOD fold 3: 0.7532\n",
      "OOD fold 4: 0.6052\n",
      "OOD fold 5: 0.5313\n",
      "In distribution: 0.8795\n",
      "OOD fold 0: 0.6494\n",
      "OOD fold 2: 0.2205\n",
      "OOD fold 3: 0.6986\n",
      "OOD fold 4: 0.5368\n",
      "OOD fold 5: 0.4647\n",
      "In distribution: 0.9123\n",
      "OOD fold 0: 0.7405\n",
      "OOD fold 2: 0.3246\n",
      "OOD fold 3: 0.7729\n",
      "OOD fold 4: 0.6621\n",
      "OOD fold 5: 0.5596\n",
      "In distribution: 0.9034\n",
      "OOD fold 0: 0.6286\n",
      "OOD fold 2: 0.1377\n",
      "OOD fold 3: 0.7083\n",
      "OOD fold 4: 0.4808\n",
      "OOD fold 5: 0.4324\n",
      "In distribution: 0.8883\n",
      "OOD fold 0: 0.6120\n",
      "OOD fold 2: 0.1915\n",
      "OOD fold 3: 0.6506\n",
      "OOD fold 4: 0.4436\n",
      "OOD fold 5: 0.4904\n",
      "Fold 0:\tood = True\t0.6687 ± 0.0973\n",
      "Fold 1:\tood = False\t0.8990 ± 0.0256\n",
      "Fold 2:\tood = True\t0.2139 ± 0.1206\n",
      "Fold 3:\tood = True\t0.7167 ± 0.0844\n",
      "Fold 4:\tood = True\t0.5457 ± 0.1563\n",
      "Fold 5:\tood = True\t0.4957 ± 0.0892\n",
      "\n",
      "In distr:\t0.8990 ± 0.0256\n",
      "OOD:\t\t0.5281 ± 0.3635\n"
     ]
    }
   ],
   "source": [
    "ood_metrics = np.zeros((n_folds, n_seeds))\n",
    "\n",
    "for seed in range(n_seeds):\n",
    "    base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/')\n",
    "    with open(os.path.join(base_dir, 'test_metrics', 'sdice_score.json')) as file:\n",
    "        metrics = json.load(file)\n",
    "\n",
    "    ids = set(dataset.df[dataset.df['fold'] == in_distr_id].index)\n",
    "    metric_keys = set(metrics.keys())\n",
    "    ids = metric_keys.intersection(ids)\n",
    "\n",
    "    in_distr_metric = np.mean([metrics[uid] for uid in ids])\n",
    "    ood_metrics[in_distr_id, seed] = in_distr_metric\n",
    "    print(f'In distribution: {in_distr_metric:.4f}')\n",
    "\n",
    "    for fold_id in ood_ids:\n",
    "        ids = list(dataset.df[dataset.df['fold'] == fold_id].index)\n",
    "\n",
    "        ood_metric = np.mean([metrics[uid] for uid in ids])\n",
    "        ood_metrics[fold_id, seed] = ood_metric\n",
    "        print(f'OOD fold {fold_id}: {ood_metric:.4f}')\n",
    "        \n",
    "means = ood_metrics.mean(axis=1)\n",
    "stds = ood_metrics.std(axis=1)\n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(f'Fold {i}:\\tood = {i != in_distr_id}\\t{means[i]:.4f} ± {1.96 * stds[i]:.4f}')\n",
    "    \n",
    "print()\n",
    "ood_ids = [i for i in range(n_folds) if i != in_distr_id]\n",
    "print(f'In distr:\\t{means[in_distr_id]:.4f} ± {1.96 * stds[in_distr_id]:.4f}')\n",
    "print(f'OOD:\\t\\t{ood_metrics[ood_ids].mean():.4f} ± {1.96 * ood_metrics[ood_ids].std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1917b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3709"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8990 - 0.5281"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d602110",
   "metadata": {},
   "source": [
    "## Baseline OOD (softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83f48f",
   "metadata": {},
   "source": [
    "#### Distance from 0.5 (softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14440489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [07:07<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833\n",
      "AUROC: 0.9982\n",
      "TNR @ 95% TPR: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [07:09<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833\n",
      "AUROC: 0.9989\n",
      "TNR @ 95% TPR: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [07:09<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833\n",
      "AUROC: 0.9973\n",
      "TNR @ 95% TPR: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [07:09<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833\n",
      "AUROC: 0.9982\n",
      "TNR @ 95% TPR: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [07:10<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833\n",
      "AUROC: 0.9981\n",
      "TNR @ 95% TPR: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "det_accs = []\n",
    "roc_aucs = []\n",
    "tprs = []\n",
    "\n",
    "for seed in range(n_seeds):\n",
    "    labels = {}\n",
    "    base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "    filenames = os.listdir(base_dir)\n",
    "    for i in tqdm(range(len(filenames))):\n",
    "        preds = load(os.path.join(base_dir, filenames[i]))\n",
    "        uncertainty_result = np.zeros_like(preds)\n",
    "        uncertainty_result[preds > 0.5] = (1 - preds)[preds > 0.5]\n",
    "        uncertainty_result[preds <= 0.5] = preds[preds <= 0.5]\n",
    "        label = uncertainty_result.mean()\n",
    "        labels[filenames[i].split('.')[0]] = label\n",
    "        \n",
    "    is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "    det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)\n",
    "    det_accs.append(det_acc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    tprs.append(tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68505a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy:\t0.9833 ± 0.0000\n",
      "AUROC:\t0.9981 ± 0.0010\n",
      "TNR @ 95% TPR:\t1.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f'Detection accuracy:\\t{np.mean(det_accs):.4f} ± {1.96 * np.std(det_accs):.4f}')\n",
    "print(f'AUROC:\\t{np.mean(roc_aucs):.4f} ± {1.96 * np.std(roc_aucs):.4f}')\n",
    "print(f'TNR @ 95% TPR:\\t{np.mean(tprs):.4f} ± {1.96 * np.std(tprs):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8faf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [05:20<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833333333333334\n",
      "AUROC: 0.9982162764771461\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "det_accs = []\n",
    "roc_aucs = []\n",
    "tprs = []\n",
    "\n",
    "for seed in [0]:\n",
    "    labels = {}\n",
    "    base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "    filenames = os.listdir(base_dir)\n",
    "    for i in tqdm(range(len(filenames))):\n",
    "        preds = load(os.path.join(base_dir, filenames[i]))\n",
    "        uncertainty_result = np.zeros_like(preds)\n",
    "        uncertainty_result[preds > 0.5] = (1 - preds)[preds > 0.5]\n",
    "        uncertainty_result[preds <= 0.5] = preds[preds <= 0.5]\n",
    "        label = uncertainty_result.mean()\n",
    "        labels[filenames[i].split('.')[0]] = label\n",
    "        \n",
    "    is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "    det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)\n",
    "    det_accs.append(det_acc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    tprs.append(tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52722ffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 3 3 3 3 3 3 0\n",
      " 0 0 3 3 3 0 3 3 1 3 0 3 3 3 0 3 0 0 3 0 0 0 3 0 3 4 0 2 3 3 3 3 3 3 3 0 0\n",
      " 4 3 3 2 3 3 0 5 0 0 3 3 0 4 3 4 0 5 0 4 3 0 2 3 2 5 3 2 3 3 4 5 0 5 3 4 4\n",
      " 4 5 0 3 0 4 5 0 5 5 5 0 0 0 5 5 4 2 0 0 2 0 0 5 5 3 5 2 2 5 5 3 4 0 0 0 5\n",
      " 5 4 0 3 5 5 5 0 5 3 2 5 5 4 0 5 3 5 5 0 5 4 3 0 3 2 5 5 2 5 0 0 3 2 3 2 0\n",
      " 4 0 5 4 2 4 2 5 5 4 2 0 5 5 4 5 5 5 2 3 3 2 4 5 5 2 0 0 4 2 4 0 4 4 5 4 4\n",
      " 4 0 5 5 5 4 2 2 3 4 4 2 3 5 2 2 5 4 4 4 4 4 4 3 2 2 4 3 2 4 0 2 5 2 3 2 5\n",
      " 5 5 4 2 2 5 2 5 2 3 4 4 2 5 0 0 4 2 4 2 5 2 4 4 4 4 0 2 2 2 0 2 2 3 2 0 4\n",
      " 4 2 5 3 5 2 4 2 0 5 5 2 2 2 4 2 4 4 2 2 3 4 0 2 2 2 4 0 4 2 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "labels_arr = np.array(list(labels.values()))\n",
    "folds = np.array([dataset.df.fold[uid] for uid in labels.keys()])\n",
    "sorted_ids = np.argsort(labels_arr)\n",
    "# print(labels_arr[sorted_ids])\n",
    "print(is_ood_true[sorted_ids])\n",
    "print(folds[sorted_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5db55d",
   "metadata": {},
   "source": [
    "#### Entropy (softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ff1c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [13:38<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833333333333334\n",
      "AUROC: 0.9983277591973244\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [15:26<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9916387959866221\n",
      "AUROC: 0.9994983277591973\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [13:18<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833333333333334\n",
      "AUROC: 0.9983277591973244\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [13:59<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833333333333334\n",
      "AUROC: 0.9984392419175028\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [13:41<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833333333333334\n",
      "AUROC: 0.998773690078038\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "det_accs = []\n",
    "roc_aucs = []\n",
    "tprs = []\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for seed in range(n_seeds):\n",
    "        labels = {}\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        filenames = os.listdir(base_dir)\n",
    "        for i in tqdm(range(len(filenames))):\n",
    "            preds = load(os.path.join(base_dir, filenames[i]))\n",
    "            uncertainty_result = - (preds * np.log2(preds + eps) + (1 - preds) * np.log2(1 - preds + eps))\n",
    "            uncertainty_result[preds == 0] = 0\n",
    "            uncertainty_result[preds == 1] = 0\n",
    "            label = uncertainty_result.mean()\n",
    "            labels[filenames[i].split('.')[0]] = label\n",
    "\n",
    "        is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "        det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)\n",
    "        det_accs.append(det_acc)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        tprs.append(tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e267620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy:\t 0.9849944258639912 ± 0.006644370122630949\n",
      "AUROC:\t 0.9986733556298774 ± 0.0008873912482556409\n",
      "TNR @ 95% TPR:\t 0.993920972644377 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Detection accuracy:\\t{np.mean(det_accs):.4f} ± {1.96 * np.std(det_accs):.4f}')\n",
    "print(f'AUROC:\\t{np.mean(roc_aucs):.4f} ± {1.96 * np.std(roc_aucs):.4f}')\n",
    "print(f'TNR @ 95% TPR:\\t{np.mean(tprs):.4f} ± {1.96 * np.std(tprs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4410a2",
   "metadata": {},
   "source": [
    "## Ensemble predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea053681",
   "metadata": {},
   "source": [
    "### Mean uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "354fbd53",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/329 [00:33<3:04:29, 33.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_120198/413257845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mensemble_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmean_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mstd_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtrue_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_segm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_preds\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbin_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbin_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    260\u001b[0m def _std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,\n\u001b[1;32m    261\u001b[0m          where=True):\n\u001b[0;32m--> 262\u001b[0;31m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0m\u001b[1;32m    263\u001b[0m                keepdims=keepdims, where=where)\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# divide by degrees of freedom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         ret = um.true_divide(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "dices = {}\n",
    "sdices = {}\n",
    "\n",
    "base_dir = os.path.join(experiment_dir, f'seed0/experiment_0/test_predictions')\n",
    "filenames = os.listdir(base_dir)\n",
    "uids = [fname.split('.')[0] for fname in filenames]\n",
    "\n",
    "for uid in tqdm(uids):\n",
    "    ensemble_preds = []\n",
    "    for seed in range(n_seeds):\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        preds = load(os.path.join(base_dir, uid + '.npy.gz'))\n",
    "        ensemble_preds.append(preds)\n",
    "    \n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    mean_preds = ensemble_preds.mean(axis=0)\n",
    "    std_preds = ensemble_preds.std(axis=0)\n",
    "    true_mask = dataset.load_segm(uid)\n",
    "    dices[uid] = dice_score(mean_preds > bin_threshold, true_mask > bin_threshold)\n",
    "    sdices[uid] = sdice_metric(mean_preds > bin_threshold, true_mask > bin_threshold, uid)\n",
    "    labels[uid] = std_preds.mean()\n",
    "        \n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f9948dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICE SCORE\n",
      "Fold 0:\tood = True\t0.9493\n",
      "Fold 1:\tood = False\t0.9816\n",
      "Fold 2:\tood = True\t0.7535\n",
      "Fold 3:\tood = True\t0.9603\n",
      "Fold 4:\tood = True\t0.9100\n",
      "Fold 5:\tood = True\t0.8978\n",
      "\n",
      "In distr:\t0.9816\n",
      "OOD:\t\t0.8942 ± 0.1453\n"
     ]
    }
   ],
   "source": [
    "print('DICE SCORE')\n",
    "ood_metrics = np.zeros((n_folds))\n",
    "metrics = dices\n",
    "\n",
    "ids = set(dataset.df[dataset.df['fold'] == in_distr_id].index)\n",
    "metric_keys = set(metrics.keys())\n",
    "ids = metric_keys.intersection(ids)\n",
    "\n",
    "in_distr_metric = np.mean([metrics[uid] for uid in ids])\n",
    "ood_metrics[in_distr_id] = in_distr_metric\n",
    "\n",
    "for fold_id in ood_ids:\n",
    "    ids = list(dataset.df[dataset.df['fold'] == fold_id].index)\n",
    "\n",
    "    ood_metric = np.mean([metrics[uid] for uid in ids])\n",
    "    ood_metrics[fold_id] = ood_metric\n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(f'Fold {i}:\\tood = {i != in_distr_id}\\t{ood_metrics[i]:.4f}')\n",
    "    \n",
    "print()\n",
    "ood_ids = [i for i in range(n_folds) if i != in_distr_id]\n",
    "print(f'In distr:\\t{ood_metrics[in_distr_id].mean():.4f}')\n",
    "print(f'OOD:\\t\\t{ood_metrics[ood_ids].mean():.4f} ± {1.96 * ood_metrics[ood_ids].std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79be877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDICE SCORE\n",
      "Fold 0:\tood = True\t0.6970\n",
      "Fold 1:\tood = False\t0.9122\n",
      "Fold 2:\tood = True\t0.1954\n",
      "Fold 3:\tood = True\t0.7538\n",
      "Fold 4:\tood = True\t0.5555\n",
      "Fold 5:\tood = True\t0.5065\n",
      "\n",
      "In distr:\t0.9122\n",
      "OOD:\t\t0.5416 ± 0.3825\n"
     ]
    }
   ],
   "source": [
    "print('SDICE SCORE')\n",
    "ood_metrics = np.zeros((n_folds))\n",
    "metrics = sdices\n",
    "\n",
    "ids = set(dataset.df[dataset.df['fold'] == in_distr_id].index)\n",
    "metric_keys = set(metrics.keys())\n",
    "ids = metric_keys.intersection(ids)\n",
    "\n",
    "in_distr_metric = np.mean([metrics[uid] for uid in ids])\n",
    "ood_metrics[in_distr_id] = in_distr_metric\n",
    "\n",
    "for fold_id in ood_ids:\n",
    "    ids = list(dataset.df[dataset.df['fold'] == fold_id].index)\n",
    "\n",
    "    ood_metric = np.mean([metrics[uid] for uid in ids])\n",
    "    ood_metrics[fold_id] = ood_metric\n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(f'Fold {i}:\\tood = {i != in_distr_id}\\t{ood_metrics[i]:.4f}')\n",
    "    \n",
    "print()\n",
    "ood_ids = [i for i in range(n_folds) if i != in_distr_id]\n",
    "print(f'In distr:\\t{ood_metrics[in_distr_id].mean():.4f}')\n",
    "print(f'OOD:\\t\\t{ood_metrics[ood_ids].mean():.4f} ± {1.96 * ood_metrics[ood_ids].std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ce593",
   "metadata": {},
   "source": [
    "### Sample diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326e5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [17:24<00:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9732998885172799\n",
      "AUROC: 0.9869565217391304\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "\n",
    "base_dir = os.path.join(experiment_dir, f'seed0/experiment_0/test_predictions')\n",
    "filenames = os.listdir(base_dir)\n",
    "uids = [fname.split('.')[0] for fname in filenames]\n",
    "\n",
    "for uid in tqdm(uids):\n",
    "    ensemble_preds = []\n",
    "    for seed in range(n_seeds):\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        preds = load(os.path.join(base_dir, uid + '.npy'))\n",
    "        ensemble_preds.append(preds)\n",
    "    \n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    mean_preds = ensemble_preds.mean(axis=0)\n",
    "    ious = []\n",
    "    for i in range(n_seeds):\n",
    "        ious.append(1 - iou(mean_preds > bin_threshold, ensemble_preds[i] > bin_threshold))\n",
    "    labels[uid] = np.mean(ious)\n",
    "        \n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2146c",
   "metadata": {},
   "source": [
    "### std(volume) / mean(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfa6f10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [05:33<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833333333333334\n",
      "AUROC: 0.9861761426978818\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "dices = {}\n",
    "\n",
    "base_dir = os.path.join(experiment_dir, f'seed0/experiment_0/test_predictions')\n",
    "filenames = os.listdir(base_dir)\n",
    "uids = [fname.split('.')[0] for fname in filenames]\n",
    "\n",
    "for uid in tqdm(uids):\n",
    "    ensemble_preds = []\n",
    "    for seed in range(n_seeds):\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        preds = load(os.path.join(base_dir, uid + '.npy'))\n",
    "        ensemble_preds.append(preds)\n",
    "    \n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    volumes = np.array([(pred > bin_threshold).sum() for pred in ensemble_preds])\n",
    "    mean_volume = volumes.mean()\n",
    "    std_volume = volumes.std()\n",
    "#     true_mask = dataset.load_segm(uid)\n",
    "#     dices[uid] = dice_score(mean_preds > bin_threshold, true_mask > bin_threshold)\n",
    "    labels[uid] = std_volume / mean_volume\n",
    "        \n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4a210",
   "metadata": {},
   "source": [
    "### Top uncertain voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40749c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [26:33<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.8946488294314381\n",
      "AUROC: 0.8011705685618729\n",
      "TNR @ 95% TPR: 0.8085106382978723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_elements = 1000000\n",
    "\n",
    "labels = {}\n",
    "dices = {}\n",
    "\n",
    "base_dir = os.path.join(experiment_dir, f'seed0/experiment_0/test_predictions')\n",
    "filenames = os.listdir(base_dir)\n",
    "uids = [fname.split('.')[0] for fname in filenames]\n",
    "\n",
    "for uid in tqdm(uids):\n",
    "    ensemble_preds = []\n",
    "    for seed in range(n_seeds):\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        preds = load(os.path.join(base_dir, uid + '.npy'))\n",
    "        sorted_preds = np.sort(preds)\n",
    "        ensemble_preds.append(sorted_preds.flatten()[-top_elements:])\n",
    "    \n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    \n",
    "#     mean_preds = ensemble_preds.mean(axis=0)\n",
    "    std_preds = ensemble_preds.std(axis=0)\n",
    "#     true_mask = dataset.load_segm(uid)\n",
    "#     dices[uid] = dice_score(mean_preds > bin_threshold, true_mask > bin_threshold)\n",
    "    labels[uid] = std_preds.mean()\n",
    "        \n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c9fd724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [24:14<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.8746376811594203\n",
      "AUROC: 0.7948160535117058\n",
      "TNR @ 95% TPR: 0.7963525835866262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_elements = 500000\n",
    "\n",
    "labels = {}\n",
    "dices = {}\n",
    "\n",
    "base_dir = os.path.join(experiment_dir, f'seed0/experiment_0/test_predictions')\n",
    "filenames = os.listdir(base_dir)\n",
    "uids = [fname.split('.')[0] for fname in filenames]\n",
    "\n",
    "for uid in tqdm(uids):\n",
    "    ensemble_preds = []\n",
    "    for seed in range(n_seeds):\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        preds = load(os.path.join(base_dir, uid + '.npy'))\n",
    "        sorted_preds = np.sort(preds)\n",
    "        ensemble_preds.append(sorted_preds.flatten()[-top_elements:])\n",
    "    \n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    \n",
    "#     mean_preds = ensemble_preds.mean(axis=0)\n",
    "    std_preds = ensemble_preds.std(axis=0)\n",
    "#     true_mask = dataset.load_segm(uid)\n",
    "#     dices[uid] = dice_score(mean_preds > bin_threshold, true_mask > bin_threshold)\n",
    "    labels[uid] = std_preds.mean()\n",
    "        \n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77fec860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [22:22<00:00,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.8729654403567447\n",
      "AUROC: 0.8016164994425864\n",
      "TNR @ 95% TPR: 0.7963525835866262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_elements = 100000\n",
    "\n",
    "labels = {}\n",
    "dices = {}\n",
    "\n",
    "base_dir = os.path.join(experiment_dir, f'seed0/experiment_0/test_predictions')\n",
    "filenames = os.listdir(base_dir)\n",
    "uids = [fname.split('.')[0] for fname in filenames]\n",
    "\n",
    "for uid in tqdm(uids):\n",
    "    ensemble_preds = []\n",
    "    for seed in range(n_seeds):\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        preds = load(os.path.join(base_dir, uid + '.npy'))\n",
    "        sorted_preds = np.sort(preds)\n",
    "        ensemble_preds.append(sorted_preds.flatten()[-top_elements:])\n",
    "    \n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    \n",
    "#     mean_preds = ensemble_preds.mean(axis=0)\n",
    "    std_preds = ensemble_preds.std(axis=0)\n",
    "#     true_mask = dataset.load_segm(uid)\n",
    "#     dices[uid] = dice_score(mean_preds > bin_threshold, true_mask > bin_threshold)\n",
    "    labels[uid] = std_preds.mean()\n",
    "        \n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02ddc5",
   "metadata": {},
   "source": [
    "### Variance instead of std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "190abcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [1:13:06<00:00, 13.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.9833333333333334\n",
      "AUROC: 0.9936454849498327\n",
      "TNR @ 95% TPR: 0.993920972644377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "dices = {}\n",
    "\n",
    "base_dir = os.path.join(experiment_dir, f'seed0/experiment_0/test_predictions')\n",
    "filenames = os.listdir(base_dir)\n",
    "uids = [fname.split('.')[0] for fname in filenames]\n",
    "\n",
    "for uid in tqdm(uids):\n",
    "    ensemble_preds = []\n",
    "    for seed in range(n_seeds):\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        preds = load(os.path.join(base_dir, uid + '.npy'))\n",
    "        ensemble_preds.append(preds)\n",
    "    \n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    mean_preds = ensemble_preds.mean(axis=0)\n",
    "    std_preds = ensemble_preds.var(axis=0)\n",
    "#     true_mask = dataset.load_segm(uid)\n",
    "#     dices[uid] = dice_score(mean_preds > bin_threshold, true_mask > bin_threshold)\n",
    "    labels[uid] = std_preds.mean()\n",
    "        \n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d77bbe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [25:14<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.705685618729097\n",
      "AUROC: 0.705685618729097\n",
      "TNR @ 95% TPR: 0.46504559270516715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_elements = 500000\n",
    "\n",
    "labels = {}\n",
    "dices = {}\n",
    "\n",
    "base_dir = os.path.join(experiment_dir, f'seed0/experiment_0/test_predictions')\n",
    "filenames = os.listdir(base_dir)\n",
    "uids = [fname.split('.')[0] for fname in filenames]\n",
    "\n",
    "for uid in tqdm(uids):\n",
    "    ensemble_preds = []\n",
    "    for seed in range(n_seeds):\n",
    "        base_dir = os.path.join(experiment_dir, f'seed{seed}/experiment_0/test_predictions')\n",
    "        preds = load(os.path.join(base_dir, uid + '.npy'))\n",
    "        sorted_preds = np.sort(preds)\n",
    "        ensemble_preds.append(sorted_preds.flatten()[-top_elements:])\n",
    "    \n",
    "    ensemble_preds = np.array(ensemble_preds)\n",
    "    \n",
    "#     mean_preds = ensemble_preds.mean(axis=0)\n",
    "    std_preds = ensemble_preds.var(axis=0)\n",
    "#     true_mask = dataset.load_segm(uid)\n",
    "#     dices[uid] = dice_score(mean_preds > bin_threshold, true_mask > bin_threshold)\n",
    "    labels[uid] = std_preds.mean()\n",
    "        \n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "det_acc, roc_auc, tpr = calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eaf936",
   "metadata": {},
   "source": [
    "## MC dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cdc9fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean var - all voxels\n",
      "Detection accuracy: 0.9816610925306577\n",
      "AUROC: 0.9900780379041249\n",
      "TNR @ 95% TPR: 0.9908814589665653\n",
      "\n",
      "Mean var - top 1000000 uncertain voxels\n",
      "Detection accuracy: 0.6053511705685619\n",
      "AUROC: 0.30641025641025643\n",
      "TNR @ 95% TPR: 0.3009118541033435\n",
      "\n",
      "Mean var - top 500000 uncertain voxels\n",
      "Detection accuracy: 0.5652173913043478\n",
      "AUROC: 0.20328874024526197\n",
      "TNR @ 95% TPR: 0.24620060790273557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5652173913043478, 0.20328874024526197, 0.24620060790273557)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p = 0.3\n",
    "\n",
    "labels = {}\n",
    "cur_labels = []\n",
    "\n",
    "labels = load('/experiments/ood_playground/cc359/mc_dropout/03/mc_drop_10/experiment_0/test_metrics/get_all_labels_var.json')\n",
    "\n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "print('Mean var - all voxels')\n",
    "calc_ood_scores(np.array(list(labels.values())), is_ood_true)\n",
    "print()\n",
    "\n",
    "labels = load('/experiments/ood_playground/cc359/mc_dropout/03/mc_drop_10/experiment_0/test_metrics/get_top_n_labels_var_1000000.json')\n",
    "print('Mean var - top 1000000 uncertain voxels')\n",
    "calc_ood_scores(np.array(list(labels.values())), is_ood_true)\n",
    "print()\n",
    "\n",
    "labels = load('/experiments/ood_playground/cc359/mc_dropout/03/mc_drop_10/experiment_0/test_metrics/get_top_n_labels_var_500000.json')\n",
    "print('Mean var - top 500000 uncertain voxels')\n",
    "calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28de9a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection accuracy: 0.6003344481605352\n",
      "AUROC: 0.317670011148272\n",
      "TNR @ 95% TPR: 0.3009118541033435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6003344481605352, 0.317670011148272, 0.3009118541033435)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p = 0.5\n",
    "\n",
    "labels = {}\n",
    "cur_labels = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "    cur_labels.append(load(f'/experiments/ood_playground/cc359/mc_dropout/05/mc_drop_res{i}/experiment_0/test_metrics/get_top_n_labels_std.json'))\n",
    "\n",
    "labels = {**cur_labels[0], **cur_labels[1], **cur_labels[2], **cur_labels[3]}\n",
    "is_ood_true = np.array([dataset.df.fold[uid] != in_distr_id for uid in labels.keys()])\n",
    "calc_ood_scores(np.array(list(labels.values())), is_ood_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1776ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
