import numpy as np
import torch
import torch.nn.functional as F

from dpipe.predict import add_extract_dims, divisible_shape
from dpipe.torch import inference_step
from dpipe.predict.shape import patches_grid
from dpipe.torch import masked_loss
from ood.torch.module.unet import UNet3DLuna
from ood.loss import focal_tversky_loss_with_nans


# loss
def criterion(logits, target):
    bce = masked_loss(~torch.isnan(target), F.binary_cross_entropy_with_logits, logits, target)
    tversky = focal_tversky_loss_with_nans(
        torch.sigmoid(logits), target, spatial_dims=(-3, -2, -1), beta=0.7, gamma=1)
    return bce + tversky


# model
architecture = UNet3DLuna(init_bias=-3)
batch_size = 5

# optimizer
batches_per_epoch = 1000
n_epochs = 30
lr = 1e-4

optimizer = torch.optim.Adam(architecture.parameters(), lr=lr)


# predict
z_patch_size = 64


@add_extract_dims(2)  # 3D -> (5D -> predict -> 5D) -> 3D
@patches_grid(z_patch_size, z_patch_size, axis=-1)  # image -> iter{patches} -> average
@divisible_shape(divisor=z_patch_size, padding_values=np.min, axis=-1)
def predict(image):
    return inference_step(image, architecture=architecture, activation=torch.sigmoid, amp=amp)


@add_extract_dims(2)  # 3D -> (5D -> predict -> 5D) -> 3D
@patches_grid(z_patch_size, z_patch_size, axis=-1)  # image -> iter{patches} -> average
@divisible_shape(divisor=z_patch_size, padding_values=np.min, axis=-1)
def predict_logit(x):
    return inference_step(x, architecture=architecture, amp=amp)
