from functools import partial

import numpy as np
import torch

from dpipe.train import Switch
from dpipe.train.policy import Schedule
from dpipe.predict import add_extract_dims, divisible_shape
from dpipe.torch import inference_step
from dpipe.predict.shape import patches_grid
from ood.torch.module.unet import UNet3D
from ood.batch_iter import SPATIAL_DIMS
from ood.loss import combined_loss_weighted, cosine_lr_schedule_fn


# loss
alpha = 0.05
adaptive_bce = False
criterion = partial(combined_loss_weighted, alpha=alpha, adaptive_bce=adaptive_bce)

# model
n_filters = 16
architecture = UNet3D(n_chans_in=n_chans_in, n_chans_out=n_chans_out, n_filters_init=n_filters)
x_patch_size = y_patch_size = np.array([64, ] * 3)
batch_size = 10

# optimizer
batches_per_epoch = 1
n_epochs = 100
lr_min = 1e-6
lr_opt = 0.005
last_linear_epoch = n_epochs // 10
lr = Switch(initial=lr_min,
            epoch_to_value={i: cosine_lr_schedule_fn(i, lr_max=lr_opt, lr_min=lr_min,
                                                     last_linear_epoch=last_linear_epoch, n_epochs=n_epochs)
                            for i in range(n_epochs)})

weight_decay = 1e-4
optimizer = torch.optim.SGD(architecture.parameters(), lr=lr_min, momentum=0.9, nesterov=True,
                            weight_decay=weight_decay)


# predict
pred_patch_size = x_patch_size
pred_patch_stride = pred_patch_size // 2


@add_extract_dims(2)  # 3D -> (5D -> predict -> 5D) -> 3D
@patches_grid(pred_patch_size, pred_patch_stride, axis=SPATIAL_DIMS)  # image -> iter{patches} -> average
@divisible_shape(divisor=[16, ] * 3, padding_values=np.min, axis=SPATIAL_DIMS)
def predict(image):
    return inference_step(image, architecture=architecture, activation=torch.sigmoid, amp=amp)
